<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="4D Dynamic Scene Editing">
  <meta name="keywords" content="4D Dynamic Scene, Dynamic Scene, 4D Dynamic Scene Editing, Dynamic Scene Editing, 4D Gaussian Editing, 4D Gaussian Splatting, 3D Gaussian Splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.svg">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://hanbyelcho.info/instruct-4dgs/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://minghanqin.github.io/AvatarSVE/">
            AvatarSVE
          </a>
        </div>
      </div> -->
    </div>

  </div>
</nav>

<!--
Joohyun Kwon https://scholar.google.com/citations?user=WilZkLEAAAAJ&hl=en
Hanbyel Cho https://hanbyelcho.info/
https://scholar.google.com/citations?user=VvNXbu8AAAAJ&hl=en
Junmo Kim https://scholar.google.com/citations?user=GdQtWNQAAAAJ&hl=en
-->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WilZkLEAAAAJ&hl=en">Joohyun Kwon</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://hanbyelcho.info/">Hanbyel Cho</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=GdQtWNQAAAAJ&hl=en">Junmo Kim</a><sup>2&#134</sup>
            </span>
            
            <span class="author-block">
              (*Equal contribution, &#134;Corresponding author)
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>DGIST, South Korea</span>
            <span class="author-block"><sup>2</sup>KAIST, South Korea</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><font color="red"><b>CVPR 2025</b></font></span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (Coming Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (Coming Soon)</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=L2OzQ91eRG4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zrporz/4DLangSplat"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1C-ciHn38vVd47TMkx2-93EUpI0z4ZdZW?usp=sharing"
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fas fa-database"></i>
                 </span>
                 <span>Data</span>
                 </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <!-- <p>
            <b>TL;DR:</b> We ground CLIP features into a set of 3D language Gaussians, which attains precise 3D language fields while being <font color="red"><b>199 &times;</b></font> faster than LERF.
          </p> -->
          <p>
            <b>TL;DR:</b> We introduce a multimodal, object-wise video prompting approach combined with a status deformable network to learn 4D language fields. Our method achieves highly precise and efficient results for both time-sensitive and time-agnostic open-vocabulary queries across multiple benchmarks.
          </p>
        </div>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/L2OzQ91eRG4"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
        <!-- TODO:Video -->
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Learning 4D language fields to enable time-sensitive, open-ended language queries in dynamic scenes is essential for many real-world applications. While LangSplat successfully grounds CLIP features into 3D Gaussian representations, achieving precision and efficiency in 3D static scenes, it lacks the ability to handle dynamic 4D fields as CLIP, designed for static image-text tasks, cannot capture temporal dynamics in videos. Real-world environments are inherently dynamic, with object semantics evolving over time. Building a precise 4D language field necessitates obtaining pixel-aligned, object-wise video features, which current vision models struggle to achieve. To address these challenges, we propose 4D LangSplat, which learns 4D language fields to handle time-agnostic or time-sensitive open-vocabulary queries in dynamic scenes efficiently. 4D LangSplat bypasses learning the language field from vision features and instead learns directly from text generated from object-wise video captions via Multimodal Large Language Models (MLLMs). Specifically, we propose a multimodal object-wise video prompting method, consisting of visual and text prompts that guide MLLMs to generate detailed, temporally consistent, high-quality captions for objects throughout a video. These captions are encoded using a Large Language Model into high-quality sentence embeddings, which then serve as pixel-aligned, object-specific feature supervision, facilitating open-vocabulary text queries through shared embedding spaces. Recognizing that objects in 4D scenes exhibit smooth transitions across states, we further propose a status deformable network to model these continuous changes over time effectively. Our results across multiple benchmarks demonstrate that 4D LangSplat attains precise and efficient results for both time-sensitive and time-agnostic open-vocabulary queries.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Visualization of Learned Features</h3>
        <div class="content has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="45%">
            <source src="./static/videos/rgblang-americano-clear.mp4"
                    type="video/mp4">
          </video>
        
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="45%">
            <source src="./static/videos/rgblang-cookie-clear.mp4"
                    type="video/mp4">
          </video>
        </div>
        

        <div class="hero-body">
          <img src="./static/images/teaser.png"/>
        </div>
        <div class="content has-text-justified">
          <p>
            Visualization of the learned language features of our 4D LangSplat. We observe that 4D LangSplat effectively learns dynamic
            semantic features that change over time, such as the gradual diffusion of coffee shown in the first two rows, and the “chicken” toggling
            between open and closed states in the latter two rows. Additionally, our semantic field captures consistent features for semantics that
            remain unchanged over time, with the clear object boundaries in the visualization demonstrating the precision of our semantic field.
          </p>
        </div>
        <h3 class="title is-4">Time-seneitive Query</h3>
        <div class="content has-text-centered">
          <video id="replay-video"
                  controls
                  muted
                  preload
                  playsinline
                  width="100%">
            <source src="./static/videos/prompt-contrast.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="hero-body">
          <img src="./static/images/time-sensitive-query.png"/>
        </div>
        <div class="content has-text-justified">
          <p>
            Visualization of time-sensitive querying results between  Deformable CLIP and ours. The bottom row depicts the cosine similarity across frames, rescaled to (0,1) for direct comparison, while the horizontal bars indicate frames identified as relevant time segments. We observed that the CLIP-based method cannot understand dynamic semantics correctly, while our method recognizes them.
          </p>
        </div>
        <h3 class="title is-4">Time-Agnostic Query</h3>
        <div class="content has-text-centered">
          <video id="replay-video"
                  controls
                  muted
                  preload
                  playsinline
                  width="100%">
            <source src="./static/videos/time-agnostic-query-dynerf.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                  controls
                  muted
                  preload
                  playsinline
                  width="100%">
            <source src="./static/videos/time-agnostic-query-hypernerf.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="hero-body">
          <img src="./static/images/time-agnostic-query1.png"/>
        </div>
        <!-- <div class="hero-body">
          <img src="./static/images/time-agnostic-query2.png"/>
        </div> -->
        <div class="content has-text-justified">
          <p>
            Comparison of time-sensitive query mask. We compare time-sensitive query masks between Deformable CLIP and ours. The CLIP-based method fails to identify time segments accurately, especially at the demarcation points during state transitions.
          </p>
        </div>
        
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    TODO:BibTeX
    <!-- <pre><code>@article{qin2023langsplat,
  title={LangSplat: 3D Language Gaussian Splatting},
  author={Qin, Minghan and Li, Wanhua and Zhou, Jiawei and Wang, Haoqian and Pfister, Hanspeter},
  journal={arXiv preprint arXiv:2312.16084},
  year={2023}
}</code></pre> -->
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <!-- <p>
            The souce code is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>,
              we thank the authors for sharing the templates.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
